<!DOCTYPE html>
<html lang="en"><head><title>Humanistic AGI</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="Humanistic AGI"/><meta property="og:description" content="This blog post is adapted from a term paper I wrote for PHIL250: Minds and Machines at UBC. Introduction Historically, development of AI has taken a very specific approach — systems that represent the world through symbols and manipulate those tokens in a systematic way to arrive at a result."/><meta property="og:image" content="https://wiki.likui.info/static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../static/icon.png"/><meta name="description" content="This blog post is adapted from a term paper I wrote for PHIL250: Minds and Machines at UBC. Introduction Historically, development of AI has taken a very specific approach — systems that represent the world through symbols and manipulate those tokens in a systematic way to arrive at a result."/><meta name="generator" content="Quartz"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link href="../static/font/font-style.css" rel="stylesheet" type="text/css" spa-preserve/><link href="../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://fonts.googleapis.com/css2?family=JetBrains Mono&amp;family=DM Serif Text:wght@400;700&amp;family=Bricolage Grotesque:ital,wght@0,350;0,600;1,400;1,600&amp;display=swap" rel="stylesheet" type="text/css" spa-preserve/><script src="../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="posts/agi"><div id="texture"></div><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h1 class="page-title"><a href="..">知识库</a></h1><div class="spacer mobile-only"></div><div class="search"><div id="search-icon"><p>Search</p><div></div><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><div class="darkmode"><input class="toggle" id="darkmode-toggle" type="checkbox" tabindex="-1"/><label id="toggle-label-light" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../posts/">所有文章</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>Humanistic AGI</a></div></nav><h1 class="article-title">Humanistic AGI</h1><p class="content-meta">Nov 03, 2020, 11 min read</p><ul class="tags"><li><a href="../tags/fruit" class="internal tag-link">#fruit</a></li></ul></div></div><article class="popover-hint"><p>This blog post is adapted from a term paper I wrote for PHIL250: Minds and Machines at UBC.</p>
<hr/>
<h2 id="introduction">Introduction<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#introduction" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Historically, development of AI has taken a very specific approach — systems that represent the world through symbols and manipulate those tokens in a systematic way to arrive at a result. This type of AI was coined Good Old-Fashioned AI (<a href="../thoughts/GOFAI" class="internal" data-slug="thoughts/GOFAI">GOFAI</a>) by John Haugeland<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref aria-describedby="footnote-label" class="internal alias">1</a></sup>.</p>
<p>This worked well up until around 1984 when the field entered an ‘AI Winter’, a long plateau in progress that was most likely due cynicism in the AI research community that trickled to media and <a href="../thoughts/funding" class="internal alias" data-slug="thoughts/funding">funding</a> bodies, halting research and development<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">2</a></sup>.</p>
<p>However, with the rise of Moore’s Law and the insane amount of compute and data available, a new approach to the development of AI arose — one that focused on statistical methods and connectionist networks like artificial <a href="../thoughts/neural-networks" class="internal alias" data-slug="thoughts/neural-networks">neural networks</a><sup><a href="#user-content-fn-2" id="user-content-fnref-2-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">2</a></sup>. Haugeland<sup><a href="#user-content-fn-1" id="user-content-fnref-1-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">1</a></sup> dubbed this approach to AI design New Fangled AI (<a href="../thoughts/NFAI" class="internal" data-slug="thoughts/NFAI">NFAI</a>).</p>
<p>This paper will examine factors that differentiate GOFAI and NFAI systems, such as their ability to adapt to changes in input, and the explainability of their outputs and internal representations. It will also examine current work in integrating the two approaches to Artificial Intelligence to create an artificial general intelligence.</p>
<h3 id="gofai-systems">GOFAI Systems<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#gofai-systems" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Since the inception of the term GOFAI, the basic idea has remained unchanged: thinking as internal symbol manipulation. Within these GOFAI systems, symbols are representative of aspects of our world. These symbols are manipulated in a systematic and logical matter, performing a series of deterministic steps that results in another sequence of symbols<sup><a href="#user-content-fn-1" id="user-content-fnref-1-3" data-footnote-ref aria-describedby="footnote-label" class="internal alias">1</a></sup>.</p>
<p>A very common example of GOFAI systems are expert systems, which are computer systems that emulate the decision making ability of a human expert<sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref aria-describedby="footnote-label" class="internal alias">3</a></sup>. They solve problems via decision-tree reasoning, figuring out whether to perform certain actions based off of if-then rules.</p>
<p>However, just being able to solve a problem shouldn’t be sufficient for intelligence. So what qualifies it? At its core, GOFAI can be considered ‘artificially intelligent’ because of semantic interpretation. If the symbols represent aspects of our world, the result, which is also a symbol sequence, can be <em>translated</em> back into aspects of our world. This is called semantic interpretation, which “seeks to construe a body of symbols so that what they mean (‘say’) turns out to be consistently reasonable and sensible, given the situation”<sup><a href="#user-content-fn-1" id="user-content-fnref-1-4" data-footnote-ref aria-describedby="footnote-label" class="internal alias">1</a></sup>.</p>
<h3 id="nfai-systems">NFAI Systems<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#nfai-systems" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>NFAI, on the other hand, is a diverse and still rapidly evolving set of systems and algorithms. It is more of a grab-bag term, roughly meaning any sort of scientific mind design that is not GOFAI<sup><a href="#user-content-fn-1" id="user-content-fnref-1-5" data-footnote-ref aria-describedby="footnote-label" class="internal alias">1</a></sup>. Under this umbrella are connectionist networks, which are networks composed of lots of simple units that are interconnected with various strengths. This paper will mostly focus on connectionism as a synecdoche for the greater umbrella of NFAI.</p>
<p>Some classic examples of connectionist networks include convolutional <a href="../thoughts/neural-networks" class="internal alias" data-slug="thoughts/neural-networks">neural networks</a> (CNNs), which are a form of image classifiers<sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref aria-describedby="footnote-label" class="internal alias">4</a></sup>. These networks operate by applying filters or kernels to an input between layers of the network. Each of those filters have their own set of strengths that will learn and evolve over time to identify certain ‘features’ from the input. Similar to cell assemblies in animal perceptual systems, these filters assemble more complex patterns using smaller and simpler patterns<sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref aria-describedby="footnote-label" class="internal alias">5</a></sup>.</p>
<p>These connectionist networks are very inspired by the structure of the brain, with its hierarchical patterns and compositional nature<sup><a href="#user-content-fn-6" id="user-content-fnref-6" data-footnote-ref aria-describedby="footnote-label" class="internal alias">6</a></sup>, rather than the rational manipulation of symbols that is observed in GOFAI.</p>
<h2 id="the-potemkin-village-analogy">The Potemkin Village Analogy<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#the-potemkin-village-analogy" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>While it is obvious that GOFAI and NFAI are very different approaches to constructing AI systems, how do they differ in their resilience to failure? An analogy that may be useful in visualizing this is a <a href="../thoughts/potemkin-village" class="internal alias" data-slug="thoughts/potemkin-village">potemkin village</a>: a fake village that is built to resemble and deceive others into thinking it is real. AI systems attempt to build a sort of ‘potemkin village’ that “works well on naturally occurring data, but is exposed as fake when one visits points in space that do not have high probability”<sup><a href="#user-content-fn-7" id="user-content-fnref-7" data-footnote-ref aria-describedby="footnote-label" class="internal alias">7</a></sup>.</p>
<p>GOFAI systems are excellent at “processing syntactical patterns like those characteristic of logical formulae, ordinary sentences, and many inferences”<sup><a href="#user-content-fn-1" id="user-content-fnref-1-6" data-footnote-ref aria-describedby="footnote-label" class="internal alias">1</a></sup>, but are also very narrow-minded and vulnerable when it comes to unexpected variations or oddities in the input given. The potemkin village that a GOFAI system may construct will hold up if only seen from the intended angles, but any slight deviation from an intended or expected input would shatter the illusion immediately.</p>
<p>NFAI systems, on the other hand, are “adept at finding various sort of similarities among patterns, at recognizing repeated (or almost repeated) patterns and filling in missing parts of incomplete patterns”<sup><a href="#user-content-fn-1" id="user-content-fnref-1-7" data-footnote-ref aria-describedby="footnote-label" class="internal alias">1</a></sup>. These also happen to be the exact things that GOFAI systems struggle with. The potemkin village that a NFAI system may construct will hold up much more robustly to unexpected patterns or noisy input, but will, at heart, still be a fake village.</p>
<h2 id="rationality-and-explainability">Rationality and explainability<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#rationality-and-explainability" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>In GOFAI systems, <a href="../thoughts/intentionality" class="internal alias" data-slug="thoughts/intentionality">intentionality</a> — the meaning and semantics behind the tokens — is injected through explicit programming by those who create it. These GOFAI systems are able to process these tokens and make conclusions based off of logic and reason rather than just trial-and-error. Case in point, expert systems. These if-then statements can easily explain decisions by showing which parts evaluated as true or false in its decision making process<sup><a href="#user-content-fn-3" id="user-content-fnref-3-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">3</a></sup>.</p>
<p><a href="../thoughts/connectionist-networks" class="internal alias" data-slug="thoughts/connectionist-networks">Connectionist networks</a>, for the most part, are very hard to explain and are often dubbed black-box models due to the hidden nature of its internal workings. Unlike GOFAI systems, its internal representation model is defined by the state of the entire network rather than that of any single unit — this is commonly referred to as a distributed model of connectionist representation<sup><a href="#user-content-fn-8" id="user-content-fnref-8" data-footnote-ref aria-describedby="footnote-label" class="internal alias">8</a></sup> and is often claimed to be one of the distinctive features of connectionism.</p>
<h2 id="models-of-representation">Models of <a href="../thoughts/representation" class="internal alias" data-slug="thoughts/representation">representation</a><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#models-of-representation" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>To put it in sound terminology, note while in the GOFAI system, the <em>tokens</em> are the objects of formal processing, so the system which manipulates the tokens is the actual vehicle of computation. The tokens themselves are also <em>representations</em> of aspects of the world, so they are also vehicles of mental content. In GOFAI systems, tokens are both the vehicle of computation and the vehicle of mental content.</p>
<p>This is in contrast with connectionist systems, where computation is performed at the level of simple units (unit activations, backpropagation), meaning the units are the vehicles of computation. However, as these systems use a distributed model of representation, it is not a single unit that represents something, but rather the “network state as a whole thats interpreted as representing”<sup><a href="#user-content-fn-8" id="user-content-fnref-8-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">8</a></sup>. Thus, in connectionist systems, the vehicles of computation (units) need to be the vehicles of representation (network state).</p>
<h2 id="integrating-gofai-and-nfai">Integrating GOFAI and NFAI<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#integrating-gofai-and-nfai" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Given that GOFAI and NFAI systems seem so vastly different in their approaches to AI, how might one go about reconciling them?</p>
<p>One approach is to combine both into one system. This is used when there’s a rational, known, and algorithmic way to process a subproblem. Systems like AlphaZero, a connectionist based Go playing system, use mixed systems to achieve the level of performance they report. Although at heart, AlphaZero uses a deep neural network to assess new positions, it also uses a Monte Carlo Tree Search (a GOFAI algorithm) to determine its next move based of the assessment of the neural net<sup><a href="#user-content-fn-9" id="user-content-fnref-9" data-footnote-ref aria-describedby="footnote-label" class="internal alias">9</a></sup>.</p>
<p>Another, less researched method, are interpretable connectionist systems. As traditional connectionist networks rely on the network state being the vehicle of representation, the complexity, depth, and scale of modern connectionist models means that it is becoming increasingly difficult for humans to interpret the output. The field of <a href="../thoughts/explainability" class="internal alias" data-slug="thoughts/explainability">explainable</a> AI (XAI) focuses on incentivizing connectionist networks to develop localist representations (i.e. moving away from having the vehicle of representation be at the network level, but at the unit level). Zhang, Wu, and Zhu of UCLA recently showed that it is possible to train a CNN to use ‘interpretable filters’, which encourage networks to group feature detectors into single filters, showing the possibility of moving from distributed representations to more local representations<sup><a href="#user-content-fn-5" id="user-content-fnref-5-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">5</a></sup>.</p>
<h3 id="what-is-agi">What is AGI?<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#what-is-agi" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>While intelligence can be understood in many ways, this paper will focus on examining the prospects of emulating or achieving the capacity to understand or learn anything a human can — the hallmark of an artificial general intelligence (AGI).</p>
<p>Most commentators would agree that current AI systems fall short of implementing general intelligence<sup><a href="#user-content-fn-4" id="user-content-fnref-4-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">4</a></sup>. These are narrow AI systems, which are used to accomplish or solve specific tasks like the game of Go or language translation, rather than to attempt to create a system capable of AGI. So, what’s stopping us from making the transition from domain-specific algorithms to domain-general algorithms?</p>
<p>One problem that stumped earlier attempts at AGI was the <em>common-sense problem</em>: how do we represent common-sense information that is obvious to most humans in a way that is accessible to AI systems that use natural language? Unsurprisingly, the problem of storing all of this information was solved by the massive explosion in compute and data in the past few decades<sup><a href="#user-content-fn-2" id="user-content-fnref-2-3" data-footnote-ref aria-describedby="footnote-label" class="internal alias">2</a></sup>. However, the difficult part of this problem, choosing what subset of that huge information bank is relevant in any situation, remains a huge unsolved problem. How do we update our database of knowledge when relationships between symbols change? This is referred to as the <a href="../thoughts/frame-problem" class="internal alias" data-slug="thoughts/frame-problem">frame problem</a>.</p>
<h3 id="dissolving-the-frame-problem">Dissolving the frame problem<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#dissolving-the-frame-problem" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Dreyfus<sup><a href="#user-content-fn-10" id="user-content-fnref-10" data-footnote-ref aria-describedby="footnote-label" class="internal alias">10</a></sup> posits that any AI systems which attempt to tackle the frame problem through storing relevant frames are bound to failure. He argues that, “human beings do not simply store common-sense information,” rather they “directly perceive and act upon significance in their environment”. In his view, a more <a href="../thoughts/Heidegger" class="internal alias" data-slug="thoughts/Heidegger">Heideggerian</a> approach to AI will dissolve this problem.</p>
<p>Heideggerian AI, in its most basic sense, is concerned with the Heideggerian concept of Dasein, which literally means ‘Being-there’<sup><a href="#user-content-fn-11" id="user-content-fnref-11" data-footnote-ref aria-describedby="footnote-label" class="internal alias">11</a></sup>. Through the use of this expression, <a href="../thoughts/Heidegger" class="internal alias" data-slug="thoughts/Heidegger">Heidegger</a> calls to attention the fact that a human cannot exist or be taken into account without existing in <a href="../thoughts/context" class="internal alias" data-slug="thoughts/context">context</a> of a world with other things — “to be human is to be fixed, embedded, and immersed in the physical, literal, tangible day to day world”<sup><a href="#user-content-fn-12" id="user-content-fnref-12" data-footnote-ref aria-describedby="footnote-label" class="internal alias">12</a></sup>.</p>
<p>Dreyfus believed that, for any AI system to achieve any sort of general intelligence, it must also exhibit Dasein. Thus, “a successful Heideggerian AI would need a perfect model of the human body – and by implication, that Dasein must be expressed as a human being, organically as well as existentially”<sup><a href="#user-content-fn-10" id="user-content-fnref-10-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">10</a></sup>.</p>
<h3 id="a-non-humanistic-approach">A non-humanistic approach<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#a-non-humanistic-approach" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>However, Steed refutes Dreyfus’ overly humanistic interpretation of Heideggerian AI, believing that a AI model only needs to be “embedded and embodied such that what AI experiences is significant for AI in the particular way that AI is,” and thus intelligence would be possible by Heideggerian standards<sup><a href="#user-content-fn-13" id="user-content-fnref-13" data-footnote-ref aria-describedby="footnote-label" class="internal alias">13</a></sup>.</p>
<p>The refutation against a purely anthropocentric view of AI brings to light an important concept: the <a href="../thoughts/multiple-realization" class="internal alias" data-slug="thoughts/multiple-realization">multiple realization</a> argument. Emulating or copying human intelligence isn’t the only way to achieve intelligence that rivals that of humans.</p>
<p>Contemporary AI systems are almost always used as a problem solving tool, a means to tackle uniquely human problems and to convey results that are semantically useful to us. As a result, these approaches are doomed to be constrained by human problems. This is the essence of the <a href="../thoughts/multiple-realization" class="internal alias" data-slug="thoughts/multiple-realization">bitter lesson of AI</a>. However, if we look outside the anthropocentric view of intelligence, AI systems may not share these human problems with us and “perhaps an authentic, free AI system does not converge to a solution that is interpretable from a human standpoint at all”<sup><a href="#user-content-fn-13" id="user-content-fnref-13-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">13</a></sup>.</p>
<p>AI is already capable of learning, adaptation, and basic Being-in-the-world. Thus, to achieve general intelligence, we should allow AI to contemplate its own problems and existence.</p>
<section data-footnotes class="footnotes"><h2 class="sr-only" id="footnote-label">Footnotes<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#footnote-label" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ol>
<li id="user-content-fn-1">
<p>Huageland, John. (1996). <em>What Is Mind Design?</em> Mind Design II, doi:10.7551/mitpress/4626.003.0001. <a href="#user-content-fnref-1" data-footnote-backref aria-label="Back to reference 1" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-1-2" data-footnote-backref aria-label="Back to reference 1-2" class="data-footnote-backref internal">↩<sup>2</sup></a> <a href="#user-content-fnref-1-3" data-footnote-backref aria-label="Back to reference 1-3" class="data-footnote-backref internal">↩<sup>3</sup></a> <a href="#user-content-fnref-1-4" data-footnote-backref aria-label="Back to reference 1-4" class="data-footnote-backref internal">↩<sup>4</sup></a> <a href="#user-content-fnref-1-5" data-footnote-backref aria-label="Back to reference 1-5" class="data-footnote-backref internal">↩<sup>5</sup></a> <a href="#user-content-fnref-1-6" data-footnote-backref aria-label="Back to reference 1-6" class="data-footnote-backref internal">↩<sup>6</sup></a> <a href="#user-content-fnref-1-7" data-footnote-backref aria-label="Back to reference 1-7" class="data-footnote-backref internal">↩<sup>7</sup></a></p>
</li>
<li id="user-content-fn-2">
<p>Hendler, J. (2008). <em>Avoiding another AI winter.</em> IEEE Intelligent Systems, (2), pp. 2-4. <a href="#user-content-fnref-2" data-footnote-backref aria-label="Back to reference 2" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-2-2" data-footnote-backref aria-label="Back to reference 2-2" class="data-footnote-backref internal">↩<sup>2</sup></a> <a href="#user-content-fnref-2-3" data-footnote-backref aria-label="Back to reference 2-3" class="data-footnote-backref internal">↩<sup>3</sup></a></p>
</li>
<li id="user-content-fn-3">
<p>Jackson, Peter (1998). <em>Introduction To Expert Systems</em> (3 ed.). Addison Wesley. p. 2. ISBN 978-0-201-87686-4. <a href="#user-content-fnref-3" data-footnote-backref aria-label="Back to reference 3" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-3-2" data-footnote-backref aria-label="Back to reference 3-2" class="data-footnote-backref internal">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-4">
<p>Buckner, C. (2019). <em>Deep learning: A philosophical introduction.</em> Philosophy Compass, 14(10), e12625. <a href="#user-content-fnref-4" data-footnote-backref aria-label="Back to reference 4" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-4-2" data-footnote-backref aria-label="Back to reference 4-2" class="data-footnote-backref internal">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-5">
<p>Zhang, Q., Nian Wu, Y., &amp; Zhu, S. C. (2018). <em>Interpretable convolutional <a href="../thoughts/neural-networks" class="internal alias" data-slug="thoughts/neural-networks">neural networks</a>.</em> In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 8827-8836). <a href="#user-content-fnref-5" data-footnote-backref aria-label="Back to reference 5" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-5-2" data-footnote-backref aria-label="Back to reference 5-2" class="data-footnote-backref internal">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-6">
<p>Churchland, P. (1990). <em>Thinking: An invitation to cognitive science.</em> Vol. 3., pp. 199-228. <a href="#user-content-fnref-6" data-footnote-backref aria-label="Back to reference 6" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-7">
<p>Goodfellow, I., Shlens, J., &amp; Szegedy, C. (2014) <em>Explaining and harnessing adversarial examples.</em> ArXiv Preprint ArXiv: 1412.6572. <a href="#user-content-fnref-7" data-footnote-backref aria-label="Back to reference 7" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-8">
<p>Crane, Tim. (2003). <em>The Mechanical Mind.</em> doi:10.4324/9780203426319. <a href="#user-content-fnref-8" data-footnote-backref aria-label="Back to reference 8" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-8-2" data-footnote-backref aria-label="Back to reference 8-2" class="data-footnote-backref internal">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-9">
<p>Silver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai, M., Guez, A., … &amp; Lillicrap, T. (2017). <em>Mastering chess and shogi by self-play with a general reinforcement learning algorithm.</em> arXiv preprint arXiv:1712.01815. <a href="#user-content-fnref-9" data-footnote-backref aria-label="Back to reference 9" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-10">
<p>Dreyfus, Hubert L. (2008) <em>Why Heideggerian AI Failed and How Fixing It Would Require Making It More Heideggerian.</em> The Mechanical Mind in History, pp. 331–362., doi:10.7551/mitpress/9780262083775.003.0014. <a href="#user-content-fnref-10" data-footnote-backref aria-label="Back to reference 10" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-10-2" data-footnote-backref aria-label="Back to reference 10-2" class="data-footnote-backref internal">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-11">
<p>Solomon, R. (1972), <em>From Rationalism to Existentialism: The Existentialists and Their Nineteenth Century Backgrounds</em>, Harper &amp; Row, New York. <a href="#user-content-fnref-11" data-footnote-backref aria-label="Back to reference 11" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-12">
<p>Steiner, G. (1978), <em>Heidegger</em>, The Harvester Press Limited, Sussex <a href="#user-content-fnref-12" data-footnote-backref aria-label="Back to reference 12" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-13">
<p>Steed, R. (2019). <em>AI is Heideggerian Enough, But Can It Be Authentic?</em> Unpublished manuscript, Carnegie Mellon. <a href="#user-content-fnref-13" data-footnote-backref aria-label="Back to reference 13" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-13-2" data-footnote-backref aria-label="Back to reference 13-2" class="data-footnote-backref internal">↩<sup>2</sup></a></p>
</li>
</ol>
</section></article></div><div class="right sidebar"><div class="graph"><h3>图谱视角</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:false,&quot;removeTags&quot;:[]}"></div><svg version="1.1" id="global-graph-icon" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
	s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
	c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
	C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
	c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
	v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
	s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
	C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
	S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
	s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
	s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:false,&quot;removeTags&quot;:[]}"></div></div></div><div class="backlinks"><h3>反向链接</h3><ul class="overflow"><li><a href="../thoughts/AI-alignment" class="internal">AI Alignment</a></li><li><a href="../thoughts/Mindstorms" class="internal">Mindstorms</a></li><li><a href="../thoughts/Neural-Correlates-of-Consciousness-(NCC)" class="internal">Neural Correlates of Consciousness (NCC)</a></li><li><a href="../thoughts/automation" class="internal">Automation</a></li><li><a href="../thoughts/data-distributions" class="internal">Data Distributions</a></li><li><a href="../thoughts/embedded-AI" class="internal">Embedded AI</a></li><li><a href="../thoughts/multiple-realization" class="internal">Multiple Realization</a></li><li><a href="../thoughts/paperclip-optimizer" class="internal">Paperclip optimizers</a></li><li><a href="../thoughts/potemkin-village" class="internal">Potemkin villages</a></li></ul></div></div></div><footer class><hr/><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.2.2</a> © 2024</p><ul><li><a href="https://github.com/ilikui">GitHub</a></li><li><a href="https://twitter.com/kico">Twitter</a></li></ul></footer></div></body><script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script type="module">
          let mermaidImport = undefined
          document.addEventListener('nav', async () => {
            if (document.querySelector("code.mermaid")) {
              mermaidImport ||= await import('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs')
              const mermaid = mermaidImport.default
              const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
              mermaid.initialize({
                startOnLoad: false,
                securityLevel: 'loose',
                theme: darkMode ? 'dark' : 'default'
              })

              await mermaid.run({
                querySelector: '.mermaid'
              })
            }
          });
          </script><script src="../postscript.js" type="module"></script></html>