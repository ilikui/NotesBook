<!DOCTYPE html>
<html lang="en"><head><title>Semantics</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="Semantics"/><meta property="og:description" content="What do words or sentences mean Meanings are public property: the same meaning be grasped by more than one person and by people at different times. Heavily related to representation Implications If this argument is correct, then the content of our thoughts partly depends on what is in the world we live in: content determines object Concept of meaning rests on two unchallenged assumptions Understanding a word (knowing its intension) was just a matter of being in a certain psychological state Meaning of a term determines its extension (actual physical manifestation / what it is) The Twin Earth Argument proves these two assumptions to be false: the extension of the term is not a function of the psychological state of the speaker by itself Sociolinguistic hypothesis Division of linguistic labour Some people wear gold rings Some people tell the difference between gold and non-gold Not everyone needs to tell the difference between gold and non-gold, rely on the judgement of experts Formally: “every linguistic community exemplifies the sort of division of linguistic labour just described; that is, it possesses at least some terms whose associated “criteria” a re known only to a subset of the speakers who acquire the terms, and whose use by the other speakers depends upon a structured cooperation between them and the speakers in the relevant subsets” Lexical Development Mental lexicon: mental dictionary of word knowledge (how it sounds, grammar, definition, etc."/><meta property="og:image" content="https://wiki.likui.info/static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../static/icon.png"/><meta name="description" content="What do words or sentences mean Meanings are public property: the same meaning be grasped by more than one person and by people at different times. Heavily related to representation Implications If this argument is correct, then the content of our thoughts partly depends on what is in the world we live in: content determines object Concept of meaning rests on two unchallenged assumptions Understanding a word (knowing its intension) was just a matter of being in a certain psychological state Meaning of a term determines its extension (actual physical manifestation / what it is) The Twin Earth Argument proves these two assumptions to be false: the extension of the term is not a function of the psychological state of the speaker by itself Sociolinguistic hypothesis Division of linguistic labour Some people wear gold rings Some people tell the difference between gold and non-gold Not everyone needs to tell the difference between gold and non-gold, rely on the judgement of experts Formally: “every linguistic community exemplifies the sort of division of linguistic labour just described; that is, it possesses at least some terms whose associated “criteria” a re known only to a subset of the speakers who acquire the terms, and whose use by the other speakers depends upon a structured cooperation between them and the speakers in the relevant subsets” Lexical Development Mental lexicon: mental dictionary of word knowledge (how it sounds, grammar, definition, etc."/><meta name="generator" content="Quartz"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link href="../static/font/font-style.css" rel="stylesheet" type="text/css" spa-preserve/><link href="../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://fonts.googleapis.com/css2?family=JetBrains Mono&amp;family=DM Serif Text:wght@400;700&amp;family=Bricolage Grotesque:ital,wght@0,350;0,600;1,400;1,600&amp;display=swap" rel="stylesheet" type="text/css" spa-preserve/><script src="../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="thoughts/semantics"><div id="texture"></div><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h1 class="page-title"><a href="..">WIKI</a></h1><div class="spacer mobile-only"></div><div class="search"><div id="search-icon"><p>Search</p><div></div><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><div class="darkmode"><input class="toggle" id="darkmode-toggle" type="checkbox" tabindex="-1"/><label id="toggle-label-light" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../thoughts/">thoughts</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>Semantics</a></div></nav><h1 class="article-title">Semantics</h1><p class="content-meta">Jul 03, 2021, 4 min read</p><ul class="tags"><li><a href="../tags/seed" class="internal tag-link">#seed</a></li></ul></div></div><article class="popover-hint"><blockquote>
<p>What do words or sentences mean</p>
</blockquote>
<p>Meanings are public property: the same meaning be grasped by more than one person and by people at different times. Heavily related to <a href="../thoughts/representation" class="internal alias" data-slug="thoughts/representation">representation</a></p>
<h2 id="implications">Implications<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#implications" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>If this argument is correct, then the content of our thoughts partly depends on what is in the world we live in: content determines object</p>
<p>Concept of meaning rests on two unchallenged assumptions</p>
<ul>
<li>Understanding a word (knowing its intension) was just a matter of being in a certain psychological state</li>
<li>Meaning of a term determines its extension (actual physical manifestation / what it is)</li>
</ul>
<p>The <a href="../thoughts/Twin-Earth-Argument" class="internal alias" data-slug="thoughts/Twin-Earth-Argument">Twin Earth Argument</a> proves these two assumptions to be false: the extension of the term is not a function of the psychological state of the speaker by itself</p>
<h2 id="sociolinguistic-hypothesis">Sociolinguistic hypothesis<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#sociolinguistic-hypothesis" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Division of linguistic labour</p>
<ul>
<li>Some people wear gold rings</li>
<li>Some people tell the difference between gold and non-gold</li>
<li>Not everyone needs to tell the difference between gold and non-gold, rely on the judgement of experts</li>
</ul>
<p>Formally: “every linguistic community exemplifies the sort of division of linguistic labour just described; that is, it possesses at least some terms whose associated “criteria” a re known only to a subset of the speakers who acquire the terms, and whose use by the other speakers depends upon a structured cooperation between them and the speakers in the relevant subsets”</p>
<h2 id="lexical-development">Lexical Development<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#lexical-development" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Mental lexicon: mental dictionary of word knowledge (how it sounds, grammar, definition, etc.)</p>
<ul>
<li>Word: symbol that refers to something</li>
<li>Symbol: stands for something without being a part of that something</li>
<li>Context-bound word: things tied to particular contexts (word use is more specific than actual meaning)</li>
<li>Nominals: names for things</li>
</ul>
<p>Natural partitions hypothesis: the physical world makes obvious the things that take nouns as labels, whereas the meanings that verbs encode have to be figured out from hearing the verb in use</p>
<p>Relational relativity hypothesis: possibility that verb meanings will vary from language to language (linguistic work showing that noun meanings are more similar across languages than are verb meanings)</p>
<p>Word extension: to what extent is a word valid?</p>
<ul>
<li>Underextensions: using words in a more restricted fashion</li>
<li>Overextensions: using words in a more broad fashion (for related study, see Naigles &amp; Gelman 1995 study, results showed that overextensions are mistakes, they don’t indicate incorrect understanding of the words)</li>
<li>Protowords (also known as phonetically consistent forms — PCFs)
<ul>
<li>Phonetically consistent: the child uses the same word every time.</li>
</ul>
</li>
<li>Things that help with accurate word extension:
<ul>
<li>Taxonomic extension: words to things are actually taxonomies (they are of the same category)</li>
</ul>
</li>
<li>Types of language use, two ends of a continuum
<ul>
<li>Referential language style: more object labels</li>
<li>Expressive language style: relatively fewer object object labels and more personal/social words</li>
</ul>
</li>
<li>Mapping problem: how do we know what the new word refers to?
<ul>
<li>Fast mapping: initial hypothesis about word meaning</li>
<li>Lexical principles/lexical constraints: guides that limit possible interpretations of new words
<ul>
<li>Whole-object assumption: words refer to whole objects</li>
<li>Assumption of mutual exclusivity: different words refer to different kinds of things. No category overlap</li>
</ul>
</li>
<li>Lexical gaps: Sometimes things are not a one-to-one match – your language may not have a lexical item for something</li>
</ul>
</li>
<li>Word spurt: see Choi &amp; Gopnik (1995)
<ul>
<li>Age at which children learn early words (first 50-100) can vary a lot due to</li>
<li>Environmental Factors
<ul>
<li>Language experience and input</li>
<li>Socioeconomic status (SES)</li>
<li>Birth order</li>
</ul>
</li>
<li>Individual Factors
<ul>
<li>Processing speed</li>
<li>Phonological memory</li>
<li>Personality and temperament</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="deep-learning-semantics">Deep Learning Semantics<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#deep-learning-semantics" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="images">Images<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#images" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Semantics in <a href="../thoughts/convolutional-neural-networks" class="internal alias" data-slug="thoughts/convolutional-neural-networks">convolutional neural networks</a></p>
<p>Hidden units often correlate semantically-meaningful concepts.</p>
<p>Inceptionism: what about, instead of weights, use backpropagation to take gradient with respect to <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. i.e., show me what you think a banana looks like</p>
<p>Style Transfer: loss function matches deep latent representation of content image <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span>:</p>
<ul>
<li>Difference between <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3217em;vertical-align:-0.2769em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">m</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em;"><span></span></span></span></span></span></span></span></span></span> for deepest <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span> between <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span></li>
<li>Intuition, deep layers <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3217em;vertical-align:-0.2769em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">m</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em;"><span></span></span></span></span></span></span></span></span></span> capture the semantics/concepts in an image, invariant to actual style</li>
</ul>
<p>Adversarial Examples: imperceptible noise that changes label/prediction. This is dangerous! We could repaint a stop sign and fool self-driving cars</p>
<p>Using semantics means it can learn bad correlations (e.g. correlating grass with cows so when it sees a cow by a beach it has no idea what it is)</p>
<p>See also: <a href="../thoughts/data-distributions" class="internal alias" data-slug="thoughts/data-distributions">data distributions</a></p></article></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:false,&quot;removeTags&quot;:[]}"></div><svg version="1.1" id="global-graph-icon" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
	s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
	c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
	C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
	c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
	v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
	s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
	C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
	S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
	s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
	s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:false,&quot;removeTags&quot;:[]}"></div></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li><a href="../thoughts/Brains-in-a-Vat" class="internal">Brains in a Vat</a></li><li><a href="../thoughts/GOFAI" class="internal">GOFAI</a></li><li><a href="../thoughts/Knowledge-Argument" class="internal">Knowledge Argument</a></li><li><a href="../thoughts/Turing-Test" class="internal">Turing Test</a></li><li><a href="../thoughts/Twin-Earth-Argument" class="internal">Twin Earth Argument</a></li><li><a href="../thoughts/Type-Theory" class="internal">Type Theory</a></li><li><a href="../thoughts/explainability" class="internal">Explainability</a></li><li><a href="../thoughts/frame-problem" class="internal">Frame Problem</a></li><li><a href="../thoughts/language" class="internal">Language</a></li><li><a href="../thoughts/machine-learning" class="internal">Machine Learning</a></li><li><a href="../thoughts/math" class="internal">Math</a></li><li><a href="../thoughts/meaning" class="internal">Meaning</a></li><li><a href="../thoughts/programming-models" class="internal">Programming Models</a></li><li><a href="../thoughts/terminology" class="internal">Terminology</a></li><li><a href="../thoughts/transformers" class="internal">Transformer Models</a></li></ul></div></div></div><footer class><hr/><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.2.2</a> © 2024</p><ul><li><a href="https://github.com/jackyzha0">GitHub</a></li><li><a href="https://twitter.com/_jzhao">Twitter</a></li></ul></footer></div></body><script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script type="module">
          let mermaidImport = undefined
          document.addEventListener('nav', async () => {
            if (document.querySelector("code.mermaid")) {
              mermaidImport ||= await import('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs')
              const mermaid = mermaidImport.default
              const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
              mermaid.initialize({
                startOnLoad: false,
                securityLevel: 'loose',
                theme: darkMode ? 'dark' : 'default'
              })

              await mermaid.run({
                querySelector: '.mermaid'
              })
            }
          });
          </script><script src="../postscript.js" type="module"></script></html>