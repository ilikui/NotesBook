<!DOCTYPE html>
<html lang="en"><head><title>Consciousness is not Information</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="Consciousness is not Information"/><meta property="og:description" content="Paper #2 for PHIL 451A Prompt 1: Is consciousness essentially a kind of information? When we examine theories of consciousness, we find that we can divide the majority of theories into two major categories: process theories and vehicle theories1."/><meta property="og:image" content="https://wiki.likui.info/static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../static/icon.png"/><meta name="description" content="Paper #2 for PHIL 451A Prompt 1: Is consciousness essentially a kind of information? When we examine theories of consciousness, we find that we can divide the majority of theories into two major categories: process theories and vehicle theories1."/><meta name="generator" content="Quartz"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link href="../static/font/font-style.css" rel="stylesheet" type="text/css" spa-preserve/><link href="../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://fonts.googleapis.com/css2?family=JetBrains Mono&amp;family=DM Serif Text:wght@400;700&amp;family=Bricolage Grotesque:ital,wght@0,350;0,600;1,400;1,600&amp;display=swap" rel="stylesheet" type="text/css" spa-preserve/><script src="../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="thoughts/Consciousness-is-not-Information"><div id="texture"></div><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h1 class="page-title"><a href="..">WIKI</a></h1><div class="spacer mobile-only"></div><div class="search"><div id="search-icon"><p>Search</p><div></div><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><div class="darkmode"><input class="toggle" id="darkmode-toggle" type="checkbox" tabindex="-1"/><label id="toggle-label-light" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../thoughts/">thoughts</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>Consciousness is not Information</a></div></nav><h1 class="article-title">Consciousness is not Information</h1><p class="content-meta">Mar 13, 2022, 7 min read</p><ul class="tags"><li><a href="../tags/fruit" class="internal tag-link">#fruit</a></li><li><a href="../tags/PHIL451A" class="internal tag-link">#PHIL451A</a></li></ul></div></div><article class="popover-hint"><blockquote>
<p>Paper #2 for PHIL 451A</p>
<p>Prompt 1: Is consciousness essentially a kind of information?</p>
</blockquote>
<p>When we examine theories of consciousness, we find that we can divide the majority of theories into two major categories: process theories and vehicle theories<sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref aria-describedby="footnote-label" class="internal alias">1</a></sup>. I further borrow terminology from Velmans<sup><a href="#user-content-fn-7" id="user-content-fnref-7" data-footnote-ref aria-describedby="footnote-label" class="internal alias">2</a></sup> to describe these as behaviourist and cognitivist approaches to consciousness respectively, and argue that consciousness under cognitivist approaches runs into quite a few glaring holes.</p>
<p>Let us first begin by defining the two major categories of theories of consciousness.</p>
<ol>
<li>Process theories assume that consciousness depends on the functional or relational properties of representational vehicles<sup><a href="#user-content-fn-6" id="user-content-fnref-6" data-footnote-ref aria-describedby="footnote-label" class="internal alias">3</a></sup>, namely on the types of computations the vehicles engage in. Process theories are also referred to as cognitivist theorists — these theories can, without scientific loss, be translated into talk about <em>information processing</em><sup><a href="#user-content-fn-7" id="user-content-fnref-7-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">2</a></sup>.</li>
<li>Vehicle theories assume that consciousness is determined by intrinsic properties of representational vehicles<sup><a href="#user-content-fn-6" id="user-content-fnref-6-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">3</a></sup>. These theories are also referred to as behaviourist theorists — these theories can, without scientific loss, be translated into talk about <em>behaviour</em><sup><a href="#user-content-fn-7" id="user-content-fnref-7-3" data-footnote-ref aria-describedby="footnote-label" class="internal alias">2</a></sup>.</li>
</ol>
<p>To ask whether consciousness is essentially a kind of information is to ask whether the cognitivist theories of consciousness should be considered true. I disagree with the cognitive theories of consciousness as they fail to adequately address several critical questions. To concretize my argument in real theories, I look to Chalmer’s process theory<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">4</a></sup> and Tononi’s Information Integration Theory<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref aria-describedby="footnote-label" class="internal alias">5</a></sup>.</p>
<p>Both of these are deeply rooted in cognitivist theories of consciousness. For example, in IIT, consciousness of the system refers to the information generated above and beyond the information generated from the separate parts of the system<sup><a href="#user-content-fn-1" id="user-content-fnref-1-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">5</a></sup>. Chalmer’s process theory posits that information states can be realized physically and that these information states themselves are conscious<sup><a href="#user-content-fn-2" id="user-content-fnref-2-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">4</a></sup>.</p>
<p>Yet, neither theory completely accounts for:</p>
<ol>
<li>Defining information in a manner at odds with how information is regularly defined</li>
<li>How a serial <a href="../thoughts/Stream-of-Consciousness" class="internal alias" data-slug="thoughts/Stream-of-Consciousness">stream of consciousness</a> can arise from a parallel distributed network</li>
<li>Information carrying in obviously non-conscious objects</li>
<li>Brute optimization of its mathematical definition</li>
</ol>
<p>We expand on each of these in turn.</p>
<p>Chalmers’ process theory starts by defining information in the world as having two aspects, physicality and phenomenality. Information then, is both a physical thing and has phenomenal intentionality (or what is is like to <em>be</em> information). In doing so, Chalmers defines information as having the property of being conscious. However, this is quite different from colloquially accepted and typical academic definitions of information. Information usually refers to <em>non-mental</em>, mind-independent entities that are embedded <em>in</em> the physical (e.g. a book or brain states). Pioneers of information theory like Claude Shannon and even colloquial usage of the term information agree with this definition. An important distinction between these two definitions is that while physical things encode and embed information, they themselves are not information. A book by itself is just an arrangement of paper and ink but it may carry information like the concept of Dante’s <em>Inferno</em>. Thus, whatever Chalmers claims to be ‘information’ cannot be the same information everyone else refers to<sup><a href="#user-content-fn-4" id="user-content-fnref-4-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">1</a></sup> and so his conclusions on the basis of information cannot be valid.</p>
<p>We then consider the seriality/stream problem in the context of Chalmers’ process theory. The ‘stream’ character of human conscious experience seems to almost be at odds with the parallel distributed model of the mind with its various synapses and neurons that have no central center for keeping order. Process theories of consciousness must therefore account for how seriality arises from the distributed nature of the mind<sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref aria-describedby="footnote-label" class="internal alias">6</a></sup>. Chalmers fails to do address this in his theory all-together. It is important to note that behaviourist theories avoid this all-together as behaviour is a <em>series</em> (or at least, very limited parallelism) of agent-environment interactions. Agents do not perform multiple complex interactions at once (e.g. eating and playing). Even for multi-tasking of simple interactions, most theories propose the concept of a bottle-neck or limiting capacity — more complex behaviours take more bandwidth and thus require more focus, required the need for serial execution.</p>
<p>Last but not least, we turn to how Chalmers’ refutes information carrying in non-conscious objects. From earlier, Chalmers defines the ability to contain information states as the capacity for consciousness<sup><a href="#user-content-fn-2" id="user-content-fnref-2-3" data-footnote-ref aria-describedby="footnote-label" class="internal alias">4</a></sup>. Yet, there are clearly non-conscious objects, books for example, that clearly carry information but are not widely accepted as being conscious. Chalmers provides two options:</p>
<ol>
<li>Perhaps only some kinds of “physically realized information spaces” are conscious.</li>
<li>Perhaps thermostats are conscious.
Chalmers’ chooses the second option and suggests that “the level of organization at which consciousness ‘winks out’ might be lower than a thermostat but higher than a rock.”<sup><a href="#user-content-fn-4" id="user-content-fnref-4-3" data-footnote-ref aria-describedby="footnote-label" class="internal alias">1</a></sup> The resolution that Chalmers’ chose is quite unsatisfying.</li>
</ol>
<p>Tononi attempts to improve on Chalmers’ theory by proposing IIT<sup><a href="#user-content-fn-4" id="user-content-fnref-4-4" data-footnote-ref aria-describedby="footnote-label" class="internal alias">1</a></sup>. In this theory, information is defined as information that is specified by a system that is irreducible to that specified by its parts. That is, information is <em>integrated</em> information. In making this distinction, Tononi explicitly rejects Chalmer’s choice of distinguishing information-carriers as conscious and instead chooses to define a subset of physically-realized information spaces (<em>integrated</em> information) as conscious. In doing so, IIT avoids the first and third pitfalls of Chalmers’ theory.</p>
<p>However, IIT still has a major flaw in that it only claims to <em>correlate</em> integrated information <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Φ</span></span></span></span> with consciousness: “To recapitulate, the theory claims that consciousness corresponds to the capacity to integrate information.”<sup><a href="#user-content-fn-1" id="user-content-fnref-1-3" data-footnote-ref aria-describedby="footnote-label" class="internal alias">5</a></sup> Yet, we know that correlation is most definitely neither definition nor causation. Even while this is a glaring hole in what IIT claims to be, we can continue to show that even the definition of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Φ</span></span></span></span> itself is problematic.</p>
<p>Roughly, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Φ</span></span></span></span> is large if the system has a lot interconnection between its components. In more technical terms, it is “minimizing, over all subdivisions of your physical system into two parts A and B, some measure of the mutual information between A’s outputs and B’s inputs and vice versa.” <sup><a href="#user-content-fn-8" id="user-content-fnref-8" data-footnote-ref aria-describedby="footnote-label" class="internal alias">7</a></sup> It is worth noting then that <em>any</em> sort of device that has some level of interconnection would be slightly conscious. According to Aaronson, Tononi seemed to accept this <a href="../thoughts/Panpsychism" class="internal alias" data-slug="thoughts/Panpsychism">panpsychist</a> implication and agree that thermostats have small but nonzero levels of consciousness. This clearly suffers the same unsatisfying conclusion that Chalmers arrived at earlier.</p>
<p>However, even more problematic, is the fact that as this is a mathematical formula, it is susceptible to optimization (see: <a href="../thoughts/Goodhart's-Law" class="internal alias" data-slug="thoughts/Goodhart's-Law">Goodhart’s Law</a>). Aaronson shows that we can construct almost trivial examples where systems that are clearly not conscious exhibit ridiculously large values of integrated information. For example, we can hook together a large number of logic gates together all in ways that are highly interconnected and achieve levels of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Φ</span></span></span></span> that imply that over half of the information in the system is integrated information. As these logic gate systems (Aaronson details these as bipartite expander graphs) can be infinitely scalable, one could theoretically construct such a system with unbounded <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Φ</span></span></span></span>. Surely there is something problematic going on if we can say that a graph of logic gates is infinitely conscious.</p>
<p>It is clear that information and information-processing based methods are brittle. Of course, there are alternatives to consider like Boris Kotchoubey’s behaviourist approaches to consciousness that I believe are more sound, it is outside the scope of this paper to discuss their viability. Earlier, we posited that cognitive theories consciousness rely on consciousness as information or information-processing. In conclusion, I have shown that key cognitivist theories of consciousness like Chalmer’s theory and Tononi’s IIT have glaring flaws in attempting to measure and define consciousness. Thus, consciousness should not be considered a kind of information.</p>
<section data-footnotes class="footnotes"><h2 class="sr-only" id="footnote-label">Footnotes<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#footnote-label" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ol>
<li id="user-content-fn-4">
<p>Pockett, Susan (2014). <em>Problems with theories that equate consciousness with information or information processing</em> <a href="#user-content-fnref-4" data-footnote-backref aria-label="Back to reference 1" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-4-2" data-footnote-backref aria-label="Back to reference 1-2" class="data-footnote-backref internal">↩<sup>2</sup></a> <a href="#user-content-fnref-4-3" data-footnote-backref aria-label="Back to reference 1-3" class="data-footnote-backref internal">↩<sup>3</sup></a> <a href="#user-content-fnref-4-4" data-footnote-backref aria-label="Back to reference 1-4" class="data-footnote-backref internal">↩<sup>4</sup></a></p>
</li>
<li id="user-content-fn-7">
<p>Velmans, M. (1991). <em>Is human information processing conscious?</em> <a href="#user-content-fnref-7" data-footnote-backref aria-label="Back to reference 2" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-7-2" data-footnote-backref aria-label="Back to reference 2-2" class="data-footnote-backref internal">↩<sup>2</sup></a> <a href="#user-content-fnref-7-3" data-footnote-backref aria-label="Back to reference 2-3" class="data-footnote-backref internal">↩<sup>3</sup></a></p>
</li>
<li id="user-content-fn-6">
<p>Atkinson, A. P., Thomas, M. S. C., and Cleeremans, A. (2000). <em>Consciousness: mapping the theoretical landscape</em> <a href="#user-content-fnref-6" data-footnote-backref aria-label="Back to reference 3" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-6-2" data-footnote-backref aria-label="Back to reference 3-2" class="data-footnote-backref internal">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-2">
<p>Chalmers, D. J. (1996). <em>The Conscious Mind: in Search of a Fundamental Theory</em> <a href="#user-content-fnref-2" data-footnote-backref aria-label="Back to reference 4" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-2-2" data-footnote-backref aria-label="Back to reference 4-2" class="data-footnote-backref internal">↩<sup>2</sup></a> <a href="#user-content-fnref-2-3" data-footnote-backref aria-label="Back to reference 4-3" class="data-footnote-backref internal">↩<sup>3</sup></a></p>
</li>
<li id="user-content-fn-1">
<p>Tononi, Giulio (2004). <em>An information integration theory of consciousness</em> <a href="#user-content-fnref-1" data-footnote-backref aria-label="Back to reference 5" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-1-2" data-footnote-backref aria-label="Back to reference 5-2" class="data-footnote-backref internal">↩<sup>2</sup></a> <a href="#user-content-fnref-1-3" data-footnote-backref aria-label="Back to reference 5-3" class="data-footnote-backref internal">↩<sup>3</sup></a></p>
</li>
<li id="user-content-fn-5">
<p>Kotchoubey, Boris (2018). <em>Human Consciousness: Where Is It From and What Is It for</em> <a href="#user-content-fnref-5" data-footnote-backref aria-label="Back to reference 6" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-8">
<p>Aaronson, Scott (2014). Why I Am Not An Integrated Information Theorist in <em><a href="https://scottaaronson.blog/?p=1799" class="external">https://scottaaronson.blog/?p=1799</a></em> <a href="#user-content-fnref-8" data-footnote-backref aria-label="Back to reference 7" class="data-footnote-backref internal alias">↩</a></p>
</li>
</ol>
</section></article></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:false,&quot;removeTags&quot;:[]}"></div><svg version="1.1" id="global-graph-icon" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
	s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
	c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
	C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
	c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
	v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
	s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
	C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
	S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
	s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
	s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:false,&quot;removeTags&quot;:[]}"></div></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li><a href="../posts/primacy-of-consciousness" class="internal">On Consciousness</a></li><li><a href="../thoughts/Integrated-Information-Theory-of-Consciousness-(IIT)" class="internal">Integrated Information Theory of Consciousness (IIT)</a></li><li><a href="../thoughts/consciousness" class="internal">Consciousness</a></li></ul></div></div></div><footer class><hr/><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.2.2</a> © 2024</p><ul><li><a href="https://github.com/jackyzha0">GitHub</a></li><li><a href="https://twitter.com/_jzhao">Twitter</a></li></ul></footer></div></body><script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script type="module">
          let mermaidImport = undefined
          document.addEventListener('nav', async () => {
            if (document.querySelector("code.mermaid")) {
              mermaidImport ||= await import('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs')
              const mermaid = mermaidImport.default
              const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
              mermaid.initialize({
                startOnLoad: false,
                securityLevel: 'loose',
                theme: darkMode ? 'dark' : 'default'
              })

              await mermaid.run({
                querySelector: '.mermaid'
              })
            }
          });
          </script><script src="../postscript.js" type="module"></script></html>